{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540a0931-2d8e-4e91-9f6b-1687fe31d514",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Please complete this Jupyter notebook and then convert it to a `.py` file called `assignment2.py`. Upload this file to Gradescope, and await feedback. \n",
    "\n",
    "You may submit as many times as you want up until the deadline. Only your latest submission counts toward your grade.\n",
    "\n",
    "Some tests are hidden and some are visible. The outcome of the visible checks will be displayed to you immediately after you submit to Gradescope. The hidden test outcomes will be revealed after final scores are published. \n",
    "\n",
    "This means that an important part of any strategy is to **start early** and **lock in all the visible test points**. After that, brainstorm what the hidden checks could be and collaborate with your teammates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc55d78-1310-41df-99c7-8e57817cc15d",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "\n",
    "Recall the derivation of the posterior when you had a binomial data point, and a uniform prior:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi(\\theta \\mid y) \n",
    "&\\propto L(y \\mid \\theta) \\pi(\\theta) \\\\\n",
    "&= \\binom{n}{y} \\theta^y (1-\\theta)^{n-y} \\mathbb{1}(0 < \\theta < 1 ) \\\\\n",
    "&\\propto\n",
    "\\theta^y (1-\\theta)^{n-y}\n",
    "\\end{align}\n",
    "\n",
    "Suppose $n=400$ and $y=250$.\n",
    "\n",
    "1.\n",
    "\n",
    "What is the natural logarithm of the normalizing constant? In other words, what do we have to divide $\\theta^y (1-\\theta)^{n-y}$ by so that it integrates to $1$? Then take the natural log of that. \n",
    "\n",
    "Stated differently, what is $\\log \\int_0^1 \\theta^y (1-\\theta)^{n-y} \\text{d} \\theta$? \n",
    "\n",
    "\n",
    "Assign your answer to `log_norm_const`\n",
    "\n",
    "NB1: if we didn't use the logarithm, the normalizing constant would be *way* too close to $0$.\n",
    "\n",
    "\n",
    "NB2: You're not doing calculus here. The integral is just a special formula, and the formula is implemented in the `scipy.special` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3236bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-267.4293217702714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special\n",
    "\n",
    "alpha = 251\n",
    "beta = 151\n",
    "\n",
    "log_norm_const = scipy.special.betaln(alpha, beta)\n",
    "log_norm_const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f234bd",
   "metadata": {},
   "source": [
    "2. \n",
    "\n",
    "Are either of these dependent on the value of $\\theta$? If yes, assign `True` to `dependent_on_theta`. Otherwise assign `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63080bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta is integrated out of the problem\n",
    "dependent_on_theta = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfa432-ac5c-402e-a33f-bec9dc2260d4",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "\n",
    "Suppose\n",
    "\n",
    "$$\\pi(\\theta) = \\text{Beta}(a,b),$$ \n",
    " \n",
    "and\n",
    "\n",
    "$$L(y \\mid \\theta) = \\text{Binomial}(n,\\theta)$$\n",
    "\n",
    "Show that $\\pi(\\theta \\mid y) = \\text{Beta}(a + y, n+b - y)$. Upload a scanned copy of your work to Gradescope portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c941e4-06f1-460e-9bcc-01ee9336c98e",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "# Step 1: Prior Distribution\n",
    "$$\\pi(\\theta) = \\text{Beta}(a, b) \\propto \\theta^{a-1} (1-\\theta)^{b-1}$$\n",
    "\n",
    "# Step 2: Likelihood Function\n",
    "$$L(y \\mid \\theta) = \\text{Binomial}(n, \\theta) \\propto \\theta^y (1-\\theta)^{n-y}$$\n",
    "\n",
    "# Step 3: Posterior Distribution using Bayes' Theorem\n",
    "$$\\pi(\\theta \\mid y) \\propto L(y \\mid \\theta) \\pi(\\theta)$$\n",
    "$$\\pi(\\theta \\mid y) \\propto \\theta^y (1-\\theta)^{n-y} \\times \\theta^{a-1} (1-\\theta)^{b-1}$$\n",
    "\n",
    "# Step 4: Combine Terms\n",
    "$$\\pi(\\theta \\mid y) \\propto \\theta^{y + (a-1)} (1-\\theta)^{(n-y) + (b-1)}$$\n",
    "\n",
    "# Step 5: Simplify the Exponents\n",
    "$$\\pi(\\theta \\mid y) \\propto \\theta^{(a+y-1)} (1-\\theta)^{(n-y+b-1)}$$\n",
    "\n",
    "# Step 6: Identify the Posterior Distribution\n",
    "$$\\pi(\\theta \\mid y) = \\text{Beta}(a + y, n + b - y)$$\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee61d5c-ab03-420a-9217-cd890cc20cd2",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "\n",
    "Suppose\n",
    "\n",
    "$$\\pi(\\theta) = \\text{Beta}(a,b),$$ \n",
    " \n",
    "for some fixed/chosen $a,b > 0$. Suppose further that you have $m > 1$ count data points $y_1, \\ldots, y_m$, each having a $\\text{Binomial}(n,\\theta)$ distribution.\n",
    "\n",
    "1. What is the likelihood of $y_1, \\ldots, y_m$ assuming they're all independent (conditioning on one $\\theta$ value)?\n",
    "2. What is the posterior distribution?\n",
    "\n",
    "Upload a scanned copy of your work to Gradescope portal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d3618-024c-4777-bd93-144eda786def",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "# Step 1: Likelihood of y_1, ..., y_m\n",
    "$$L(y_i \\mid \\theta) \\propto \\theta^{y_i} (1-\\theta)^{n-y_i}$$\n",
    "\n",
    "# Joint Likelihood assuming independence\n",
    "$$L(y_1, \\ldots, y_m \\mid \\theta) \\propto \\prod_{i=1}^m L(y_i \\mid \\theta) \\propto \\prod_{i=1}^m \\left(\\theta^{y_i} (1-\\theta)^{n-y_i} \\right)$$\n",
    "\n",
    "# Simplifying the product of binomial coefficients, ANSWER:\n",
    "$$L(y_1, \\ldots, y_m \\mid \\theta) \\propto \\left( \\prod_{i=1}^m \\right) \\theta^{\\sum_{i=1}^m y_i} (1-\\theta)^{\\sum_{i=1}^m (n-y_i)}$$\n",
    "\n",
    "# Step 2: Posterior Distribution using Bayes' Theorem\n",
    "$$\\pi(\\theta \\mid y_1, \\ldots, y_m) \\propto L(y_1, \\ldots, y_m \\mid \\theta) \\pi(\\theta)$$\n",
    "\n",
    "# Substitute prior and likelihood\n",
    "$$\\pi(\\theta \\mid y_1, \\ldots, y_m) \\propto \\theta^{\\sum_{i=1}^m y_i} (1-\\theta)^{mn - \\sum_{i=1}^m y_i} \\times \\theta^{a-1} (1-\\theta)^{b-1}$$\n",
    "\n",
    "# Combine terms involving Theta\n",
    "$$\\pi(\\theta \\mid y_1, \\ldots, y_m) \\propto \\theta^{\\sum_{i=1}^m y_i + a - 1} (1-\\theta)^{mn - \\sum_{i=1}^m y_i + b - 1}$$\n",
    "\n",
    "# Identify the Posterior Distribution\n",
    "$$ \\pi(\\theta \\mid y_1, \\ldots, y_m) = \\text{Beta}(a + \\sum_{i=1}^m y_i, b + mn - \\sum_{i=1}^m y_i)$$ \n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2ebc5-cd7f-4931-92c2-6ece56286080",
   "metadata": {},
   "source": [
    "### Problem 4: Roulette!\n",
    "\n",
    "In the game of **Roulette** the croupier spins a wheel and a ball, and you bet on where the ball will end up. Suppose you're interested in testing whether all possible outcomes are equally likely. Consider the fake data below.\n",
    "\n",
    "![roulette.jpg](roulette.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d01f96-5695-459b-a6e4-9384c3f90d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  color\n",
       "0      30  black\n",
       "1      31    red\n",
       "2       5    red\n",
       "3       9    red\n",
       "4      14  black"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not edit this cell!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the possible numbers on the roulette wheel\n",
    "numbers = np.arange(0, 38)  # 0 to 36 for numbers, 37 for double zero\n",
    "# Define the colors of the numbers\n",
    "colors = ['green'] + ['red', 'black'] * 18  + ['green']\n",
    "\n",
    "num_rows = 100\n",
    "my_data = pd.DataFrame({'number':np.random.choice(numbers, num_rows)})\n",
    "my_data['color'] = my_data.number.apply( lambda num : colors[num])\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358598ac-a481-460c-8a56-6644a7eb3518",
   "metadata": {},
   "source": [
    "Suppose $\\theta$ is the probability the ball lands on red.\n",
    "\n",
    "1. Choose a Beta prior for $\\theta$. Assign your prior hyperparameters to the variables `prior_hyperparam1` and `prior_hyperparam2`. Make sure the mean of your prior is $18/38$!\n",
    "\n",
    "Hint: do the previous problem first, and notice that, in this case, $n=1$ and $m=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6756f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a/a+b = 18/38\n",
    "# simplify and end up with a/b = 9/10\n",
    "# Mean of Beta = a/a+b, 9/9+10 = 9/18 = 18/38\n",
    "prior_hyperparam1 = 9\n",
    "prior_hyperparam2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b6538",
   "metadata": {},
   "source": [
    "2. Use the simulated data above, and come up with a posterior. Assign the parameters of the beta distribution to `posterior_hyperparam1` and `posterior_hyperparam2`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35427b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_red = my_data[my_data['color'] == 'red'].shape[0]\n",
    "num_non_red = my_data[my_data['color'] != 'red'].shape[0]\n",
    "\n",
    "#posterior_hyperparam1 = a + y\n",
    "#posterior_hyperparam2 = b + (n-y)\n",
    "\n",
    "posterior_hyperparam1 = prior_hyperparam1 + num_red\n",
    "posterior_hyperparam2 = prior_hyperparam2 + num_non_red\n",
    "\n",
    "posterior_hyperparam1, posterior_hyperparam2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83cba2",
   "metadata": {},
   "source": [
    "3. Calculate a 95% *credible interval* for theta. Assign your answer to a `tuple` called `my_interval`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df8df09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37374578055917035, 0.5518283947537816)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "lower_bound = stats.beta.ppf(0.025, posterior_hyperparam1, posterior_hyperparam2)\n",
    "upper_bound = stats.beta.ppf(0.975, posterior_hyperparam1, posterior_hyperparam2)\n",
    "\n",
    "my_interval = (lower_bound, upper_bound)\n",
    "\n",
    "my_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3d7a0",
   "metadata": {},
   "source": [
    "4. Simulate $1000$ times from the posterior predictive distribution. Call your samples `post_pred_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb43980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_simulations = 1000\n",
    "\n",
    "posterior_samples = stats.beta.rvs(posterior_hyperparam1, posterior_hyperparam2, size=num_simulations)\n",
    "post_pred_samples = np.random.binomial(1, posterior_samples, size=num_simulations)\n",
    "\n",
    "post_pred_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a0223-ac26-445e-9d40-c914728265e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
